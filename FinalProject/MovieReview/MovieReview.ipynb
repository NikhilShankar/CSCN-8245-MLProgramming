{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Get Latest Videos and Comments**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import requests\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "class MovieReviewScraper:\n",
    "    def __init__(self, tmdb_api_key, youtube_api_key):\n",
    "        self.tmdb_api_key = tmdb_api_key\n",
    "        self.youtube_api_key = youtube_api_key\n",
    "        self.tmdb_base_url = \"https://api.themoviedb.org/3\"\n",
    "        self.youtube_base_url = \"https://www.googleapis.com/youtube/v3\"\n",
    "    \n",
    "    def get_release_date(self, movie_name):\n",
    "        \"\"\"Get the release date of the movie from TMDB.\"\"\"\n",
    "        search_url = f\"{self.tmdb_base_url}/search/movie\"\n",
    "        params = {\n",
    "            \"api_key\": self.tmdb_api_key,\n",
    "            \"query\": movie_name\n",
    "        }\n",
    "        response = requests.get(search_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if data['results']:\n",
    "            release_date = data['results'][0]['release_date']\n",
    "            country = data['results'][0].get('original_language', 'US')  # Default to US\n",
    "            print(f\"Movie Found: {movie_name} | Release Date: {release_date}\")\n",
    "            return release_date, country\n",
    "        else:\n",
    "            raise ValueError(f\"Movie '{movie_name}' not found on TMDB.\")\n",
    "\n",
    "    def search_youtube_videos(self, movie_name, release_date, country_code):\n",
    "        \"\"\"Search for YouTube videos uploaded within a week of the movie release.\"\"\"\n",
    "        start_date = release_date\n",
    "        end_date = (datetime.strptime(release_date, \"%Y-%m-%d\") + timedelta(days=7)).strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        search_url = f\"{self.youtube_base_url}/search\"\n",
    "        params = {\n",
    "            \"part\": \"snippet\",\n",
    "            \"q\": f\"{movie_name} review\",\n",
    "            \"type\": \"video\",\n",
    "            \"regionCode\": country_code,\n",
    "            \"publishedAfter\": f\"{start_date}T00:00:00Z\",\n",
    "            \"publishedBefore\": f\"{end_date}T23:59:59Z\",\n",
    "            \"key\": self.youtube_api_key,\n",
    "            \"maxResults\": 50  # Maximum results per page\n",
    "        }\n",
    "        response = requests.get(search_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        video_ids = [item['id']['videoId'] for item in data.get('items', [])]\n",
    "        print(f\"Found {len(video_ids)} videos for '{movie_name}' reviews.\")\n",
    "        return video_ids\n",
    "\n",
    "    def get_video_comments(self, video_id):\n",
    "        \"\"\"Fetch comments from a YouTube video.\"\"\"\n",
    "        comments = []\n",
    "        comments_url = f\"{self.youtube_base_url}/commentThreads\"\n",
    "        params = {\n",
    "            \"part\": \"snippet\",\n",
    "            \"videoId\": video_id,\n",
    "            \"key\": self.youtube_api_key,\n",
    "            \"maxResults\": 100  # Fetch maximum per page\n",
    "        }\n",
    "\n",
    "        while len(comments) < 200:  # Limit to 200 comments\n",
    "            response = requests.get(comments_url, params=params)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "\n",
    "            for item in data.get('items', []):\n",
    "                comments.append(item['snippet']['topLevelComment']['snippet']['textOriginal'])\n",
    "\n",
    "            next_page_token = data.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break\n",
    "            params['pageToken'] = next_page_token\n",
    "\n",
    "        print(f\"Fetched {len(comments)} comments for video ID: {video_id}\")\n",
    "        return comments[:200]\n",
    "\n",
    "    def save_to_csv(self, movie_name, comments):\n",
    "        \"\"\"Save comments to a CSV file.\"\"\"\n",
    "        filename = f\"{movie_name.replace(' ', '_')}_comments.csv\"\n",
    "        with open(filename, mode='w', encoding='utf-8', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Comment\"])\n",
    "            writer.writerows([[comment] for comment in comments])\n",
    "        print(f\"Comments saved to {filename}\")\n",
    "\n",
    "    def scrape_movie_reviews(self, movie_name):\n",
    "        \"\"\"Main function to scrape movie reviews.\"\"\"\n",
    "        try:\n",
    "            release_date, country = self.get_release_date(movie_name)\n",
    "            video_ids = self.search_youtube_videos(movie_name, release_date, country)\n",
    "            \n",
    "            all_comments = []\n",
    "            for video_id in video_ids:\n",
    "                all_comments.extend(self.get_video_comments(video_id))\n",
    "                if len(all_comments) >= 200:  # Limit total comments\n",
    "                    break\n",
    "            \n",
    "            self.save_to_csv(movie_name, all_comments)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# scraper = MovieReviewScraper(\"YOUR_TMDB_API_KEY\", \"YOUR_YOUTUBE_API_KEY\")\n",
    "# scraper.scrape_movie_reviews(\"Inception\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
